{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"alto2txt2fixture alto2txt2fixture is a standalone tool that converts our alto2txt metadata into JSON data with corresponding relational IDs and corrected data for easy ingestion into a relational database using, for example, Django.","title":"alto2txt2fixture"},{"location":"#alto2txt2fixture","text":"alto2txt2fixture is a standalone tool that converts our alto2txt metadata into JSON data with corresponding relational IDs and corrected data for easy ingestion into a relational database using, for example, Django.","title":"alto2txt2fixture"},{"location":"running/","text":"Using poetry to run The program should run automatically with the following command: $ poetry run Alternatively, if you want to add optional parameters and don\u2019t want to use the standard poetry script to run, you can use the (somewhat convoluted) poetry run run.py and provide any optional parameters. You can see a list of all the \u201cOptional parameters\u201d below. For example, if you want to only include the hmd collection: $ poetry run run.py --collections hmd Alternative: Run the script without poetry If you find yourself in trouble with poetry , the program should run perfectly fine on its own as well. The same command, then, would be: $ python run.py --collections hmd Optional parameters The program has a number of optional parameters that you can choose to include or not. The table below describes each parameter, how to pass it to the program, and what its defaults are. Flag Description Default value -c , --collections Which collections to process in the mounted alto2txt directory hmd, lwm, jisc, bna -o , --output Into which directory should the processed files be put? ./output/fixtures/ -m , --mountpoint Where is the alto2txt directories mounted? ./input/alto2txt/ Successfully running the program: An example","title":"Running the Program"},{"location":"running/#using-poetry-to-run","text":"The program should run automatically with the following command: $ poetry run Alternatively, if you want to add optional parameters and don\u2019t want to use the standard poetry script to run, you can use the (somewhat convoluted) poetry run run.py and provide any optional parameters. You can see a list of all the \u201cOptional parameters\u201d below. For example, if you want to only include the hmd collection: $ poetry run run.py --collections hmd","title":"Using poetry to run"},{"location":"running/#alternative-run-the-script-without-poetry","text":"If you find yourself in trouble with poetry , the program should run perfectly fine on its own as well. The same command, then, would be: $ python run.py --collections hmd","title":"Alternative: Run the script without poetry"},{"location":"running/#optional-parameters","text":"The program has a number of optional parameters that you can choose to include or not. The table below describes each parameter, how to pass it to the program, and what its defaults are. Flag Description Default value -c , --collections Which collections to process in the mounted alto2txt directory hmd, lwm, jisc, bna -o , --output Into which directory should the processed files be put? ./output/fixtures/ -m , --mountpoint Where is the alto2txt directories mounted? ./input/alto2txt/","title":"Optional parameters"},{"location":"running/#successfully-running-the-program-an-example","text":"","title":"Successfully running the program: An example"},{"location":"understanding-results/","text":"The resulting file structure The examples below follow standard settings If you choose other settings for when you run the program, your output directory may look different from the information on this page. Reports Reports are automatically generated with a unique hash as the overarching folder structure. Inside the reports directory, you\u2019ll find a JSON file for each alto2txt directory (organised by NLP identifier). The report structure, thus, looks like this: The JSON file has some good troubleshooting information. You\u2019ll find that the contents are structured as a Python dictionary (or JavaScript Object ). Here is an example: Here is an explanation of each of the keys in the dictionary: Key Explanation Data type path The input path for the zip file that is being converted. string bytes The size of the input zip file represented in bytes. integer size The size of the input zip file represented in a human-readable string. string contents #TODO #3 integer start Date and time when processing started (see also end below). datestring newspaper_paths #TODO #3 list ( string ) publication_codes A list of the NLPs that are contained in the input zip file. list ( string ) issue_paths A list of all the issue paths that are contained in the cache directory. list ( string ) item_paths A list of all the item paths that are contained in the cache directory. list ( string ) end Date and time when processing ended (see also start above). datestring seconds Seconds that the script spent interpreting the zip file (should be added to the microseconds below). integer microseconds Microseconds that the script spent interpreting the zip file (should be added to the seconds above). integer Fixtures The most important output of the script is contained in the fixtures directory. This directory contains JSON files for all the different columns in the corresponding Django metadata database (i.e. DataProvider , Digitisation , Ingest , Issue , Newspaper , and Item ). The numbering at the end of each file indicates the order of the files as they are divided into a maximum of 2e6 elements*: Each JSON file contains a Python-like list (JavaScript Array ) of dictionaries (JavaScript Objects ), which have a primary key ( pk ), the related database model (in the example below the Django newspapers app\u2019s newspaper table), and a nested dictionary / Object which contains all the values for the database\u2019s table entry: * The maximum elements per file can be adjusted in the settings.py file\u2019s settings object\u2019s MAX_ELEMENTS_PER_FILE value.","title":"Understanding the Results"},{"location":"understanding-results/#the-resulting-file-structure","text":"The examples below follow standard settings If you choose other settings for when you run the program, your output directory may look different from the information on this page.","title":"The resulting file structure"},{"location":"understanding-results/#reports","text":"Reports are automatically generated with a unique hash as the overarching folder structure. Inside the reports directory, you\u2019ll find a JSON file for each alto2txt directory (organised by NLP identifier). The report structure, thus, looks like this: The JSON file has some good troubleshooting information. You\u2019ll find that the contents are structured as a Python dictionary (or JavaScript Object ). Here is an example: Here is an explanation of each of the keys in the dictionary: Key Explanation Data type path The input path for the zip file that is being converted. string bytes The size of the input zip file represented in bytes. integer size The size of the input zip file represented in a human-readable string. string contents #TODO #3 integer start Date and time when processing started (see also end below). datestring newspaper_paths #TODO #3 list ( string ) publication_codes A list of the NLPs that are contained in the input zip file. list ( string ) issue_paths A list of all the issue paths that are contained in the cache directory. list ( string ) item_paths A list of all the item paths that are contained in the cache directory. list ( string ) end Date and time when processing ended (see also start above). datestring seconds Seconds that the script spent interpreting the zip file (should be added to the microseconds below). integer microseconds Microseconds that the script spent interpreting the zip file (should be added to the seconds above). integer","title":"Reports"},{"location":"understanding-results/#fixtures","text":"The most important output of the script is contained in the fixtures directory. This directory contains JSON files for all the different columns in the corresponding Django metadata database (i.e. DataProvider , Digitisation , Ingest , Issue , Newspaper , and Item ). The numbering at the end of each file indicates the order of the files as they are divided into a maximum of 2e6 elements*: Each JSON file contains a Python-like list (JavaScript Array ) of dictionaries (JavaScript Objects ), which have a primary key ( pk ), the related database model (in the example below the Django newspapers app\u2019s newspaper table), and a nested dictionary / Object which contains all the values for the database\u2019s table entry: * The maximum elements per file can be adjusted in the settings.py file\u2019s settings object\u2019s MAX_ELEMENTS_PER_FILE value.","title":"Fixtures"},{"location":"tutorial/first-steps/","text":"Installing The installation process should be fairly easy to take care of, using poetry : $ poetry install However, this is only the first step in the process. As the script works through the alto2txt collections, you will either need to choose the slower option \u2014 mounting them to your computer (using blobfuse ) \u2014 or the faster option \u2014 downloading the required zip files from the Azure storage to your local hard drive. In the two following sections, both of those options are described. Connecting alto2txt to the program Downloading local copies of alto2txt on your computer This option will take up a lot of hard drive space As of the time of writing, downloading all of alto2txt\u2019s metadata takes up about 185GB on your local drive. You do not have to download all of the collections or all of the zip files for each collection, as long as you are aware that the resulting fixtures will be limited in scope. Step 1: Log in to Azure using Microsoft Azure Storage Explorer Microsoft Azure Storage Explorer (MASE) is a great and free tool for downloading content off Azure. Your first step is to download and install this product on your local computer. Once you have opened MASE, you will need to sign into the appropriate Azure account. Step 2: Download the alto2txt blob container to your hard drive On your left-hand side, you should see a menu where you can navigate to the correct \u201cblob container\u201d: Living with Machines > Storage Accounts > alto2txt > Blob Containers : You will want to replicate the same structure as the Blob Container itself in a folder on your hard drive: Once you have the structure set up, you are ready to download all of the files needed. For each of the blob containers, make sure that you download the metadata directory only onto your computer: Select all of the files and press the download button: Make sure you save all the zip files inside the correct local folder: The \u201cActivities\u201d bar will now show you the progress and speed: Mounting alto2txt on your computer This option will only work on a Linux or UNIX computer If you have a mac, your only option is the one below. Step 1: Install BlobFuse Follow the instructions for installing BlobFuse and the instructions for how to prepare your drive for mounting . Step 2: Set up SAS tokens Follow the instructions for setting up access to your Azure storage account . Step 3: Mount your blobs TODO #3: Write this section. Note that you can also search on the internet for ideas on how to create local scripts to facilitate easier connection next time.","title":"First Steps"},{"location":"tutorial/first-steps/#installing","text":"The installation process should be fairly easy to take care of, using poetry : $ poetry install However, this is only the first step in the process. As the script works through the alto2txt collections, you will either need to choose the slower option \u2014 mounting them to your computer (using blobfuse ) \u2014 or the faster option \u2014 downloading the required zip files from the Azure storage to your local hard drive. In the two following sections, both of those options are described.","title":"Installing"},{"location":"tutorial/first-steps/#connecting-alto2txt-to-the-program","text":"","title":"Connecting alto2txt to the program"},{"location":"tutorial/first-steps/#downloading-local-copies-of-alto2txt-on-your-computer","text":"This option will take up a lot of hard drive space As of the time of writing, downloading all of alto2txt\u2019s metadata takes up about 185GB on your local drive. You do not have to download all of the collections or all of the zip files for each collection, as long as you are aware that the resulting fixtures will be limited in scope.","title":"Downloading local copies of alto2txt on your computer"},{"location":"tutorial/first-steps/#step-1-log-in-to-azure-using-microsoft-azure-storage-explorer","text":"Microsoft Azure Storage Explorer (MASE) is a great and free tool for downloading content off Azure. Your first step is to download and install this product on your local computer. Once you have opened MASE, you will need to sign into the appropriate Azure account.","title":"Step 1: Log in to Azure using Microsoft Azure Storage Explorer"},{"location":"tutorial/first-steps/#step-2-download-the-alto2txt-blob-container-to-your-hard-drive","text":"On your left-hand side, you should see a menu where you can navigate to the correct \u201cblob container\u201d: Living with Machines > Storage Accounts > alto2txt > Blob Containers : You will want to replicate the same structure as the Blob Container itself in a folder on your hard drive: Once you have the structure set up, you are ready to download all of the files needed. For each of the blob containers, make sure that you download the metadata directory only onto your computer: Select all of the files and press the download button: Make sure you save all the zip files inside the correct local folder: The \u201cActivities\u201d bar will now show you the progress and speed:","title":"Step 2: Download the alto2txt blob container to your hard drive"},{"location":"tutorial/first-steps/#mounting-alto2txt-on-your-computer","text":"This option will only work on a Linux or UNIX computer If you have a mac, your only option is the one below.","title":"Mounting alto2txt on your computer"},{"location":"tutorial/first-steps/#step-1-install-blobfuse","text":"Follow the instructions for installing BlobFuse and the instructions for how to prepare your drive for mounting .","title":"Step 1: Install BlobFuse"},{"location":"tutorial/first-steps/#step-2-set-up-sas-tokens","text":"Follow the instructions for setting up access to your Azure storage account .","title":"Step 2: Set up SAS tokens"},{"location":"tutorial/first-steps/#step-3-mount-your-blobs","text":"TODO #3: Write this section. Note that you can also search on the internet for ideas on how to create local scripts to facilitate easier connection next time.","title":"Step 3: Mount your blobs"}]}